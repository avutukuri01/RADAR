{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d24dab8b-17df-4e5f-991a-6f833274ca9f",
   "metadata": {},
   "source": [
    "# Preprocessing Notebook\n",
    "\n",
    "**Purpose:** Prepare the dataset for training and evaluation.  \n",
    "**Pipeline order:** This notebook must be run first, before `training.ipynb` and `errordatasetcreation.ipynb`.\n",
    "\n",
    "**Inputs required:**\n",
    "- VinDr-CXR dataset (unzipped in `vinbigdata-chest-xray-abnormalities-detection/`)\n",
    "\n",
    "**Outputs:**\n",
    "- Preprocessed CSVs and PNG images for training, validation, and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a8a031",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8c6a97a-5e9b-4c75-93aa-c9e7c9c38a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pydicom\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import random\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763f582c-eb15-426c-b108-83f20897ba13",
   "metadata": {},
   "source": [
    "# Preprocessing Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2beb3c7-a316-4ad1-9a49-a2cd6cf9ea23",
   "metadata": {},
   "source": [
    "## Rescale Bounding Boxes to 1024Ã—1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a07282e-9ee9-4442-94cc-5942c994355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r\"vinbigdata-chest-xray-abnormalities-detection\\train\"\n",
    "\n",
    "TARGET_SIZE = 1024\n",
    "\n",
    "csv_path = Path(\"vinbigdata-chest-xray-abnormalities-detection/train.csv\")\n",
    "dicom_folder = Path(\"vinbigdata-chest-xray-abnormalities-detection/train\")\n",
    "output_csv = Path(\"preprocessed_1024.csv\")\n",
    "TARGET_SIZE = 1024\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "for idx in data.index:\n",
    "    if data.at[idx, \"class_id\"] != 14:\n",
    "        dicom_file = dicom_folder / f\"{data.at[idx, 'image_id']}.dicom\"\n",
    "        if not dicom_file.exists():\n",
    "            print(f\"Warning: {dicom_file} not found, skipping.\")\n",
    "            continue\n",
    "        ds = pydicom.dcmread(str(dicom_file))\n",
    "        height, width = ds.pixel_array.shape\n",
    "        scale_x = TARGET_SIZE / width\n",
    "        scale_y = TARGET_SIZE / height\n",
    "\n",
    "        xmin = float(data.at[idx, \"x_min\"])\n",
    "        ymin = float(data.at[idx, \"y_min\"])\n",
    "        xmax = float(data.at[idx, \"x_max\"])\n",
    "        ymax = float(data.at[idx, \"y_max\"])\n",
    "\n",
    "        data.at[idx, \"x_min\"] = int(xmin * scale_x)\n",
    "        data.at[idx, \"y_min\"] = int(ymin * scale_y)\n",
    "        data.at[idx, \"x_max\"] = int(xmax * scale_x)\n",
    "        data.at[idx, \"y_max\"] = int(ymax * scale_y)\n",
    "\n",
    "# Save output\n",
    "data.to_csv(output_csv, index=False)\n",
    "print(f\"Saved {output_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4994ac2f-0837-4985-9e6d-bf8a08b2ce4c",
   "metadata": {},
   "source": [
    "## Split into training, validation, and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e296f3-ceb3-441c-8f65-806f7f9b3557",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"preprocessed_1024.csv\")\n",
    "\n",
    "image_ids = data['image_id'].unique()\n",
    "\n",
    "ids_training_validation, ids_testing = train_test_split(image_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "image_ids_train, image_ids_val = train_test_split(ids_training_validation, test_size=0.2, random_state=42)\n",
    "\n",
    "group_test = data[data['image_id'].isin(ids_testing)]\n",
    "group_train = data[data['image_id'].isin(image_ids_train)]\n",
    "group_val = data[data['image_id'].isin(image_ids_val)]\n",
    "\n",
    "group_test.to_csv(\"testing.csv\", index=False)\n",
    "group_train.to_csv(\"training.csv\", index=False)\n",
    "group_val.to_csv(\"validation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42dc3f7-fca5-4625-942a-947bc1a8eb45",
   "metadata": {},
   "source": [
    "# Preprocessing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a449e6f-be86-4947-a2c6-306a2d370e33",
   "metadata": {},
   "source": [
    "## Convert images from DICOM to PNG and resize to 1024x1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef96c60-22ca-4e4f-8d4c-3d8b47d2fd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DICOM_DIR   = Path(r\"vinbigdata-chest-xray-abnormalities-detection\\train\")\n",
    "OUTPUT_DIR  = Path(r\"images\")\n",
    "TARGET_SIZE = 1024\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for dcm_path in DICOM_DIR.glob(\"*.dcm\"):\n",
    "    ds  = pydicom.dcmread(dcm_path)\n",
    "    arr = ds.pixel_array.astype(np.float32)\n",
    "\n",
    "    arr -= arr.min()\n",
    "    if arr.max() != 0:\n",
    "        arr = (arr / arr.max()) * 255.0\n",
    "    arr = arr.astype(np.uint8)\n",
    "\n",
    "    img = Image.fromarray(arr, mode=\"L\")\n",
    "\n",
    "    img = img.resize((TARGET_SIZE, TARGET_SIZE), resample=Image.LANCZOS)\n",
    "\n",
    "    out_path = OUTPUT_DIR / f\"{dcm_path.stem}.png\"\n",
    "    img.save(out_path)\n",
    "\n",
    "    print(f\"Saved {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fdc8d1-4498-4d83-a274-ddad678e4fcb",
   "metadata": {},
   "source": [
    "## Split images into training, validation, and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c947fe6e-5305-4be6-bfce-ecc007b5c67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing images\n",
    "input_folder = \"images\"\n",
    "\n",
    "# CSV listing id's for split\n",
    "train_csv = \"training.csv\"\n",
    "validation_csv = \"validation.csv\"\n",
    "test_csv = \"testing.csv\"\n",
    "\n",
    "# Where to put each split\n",
    "train_folder = \"YOLODataset/train/images\"\n",
    "validation_folder = \"YOLODataset/val/images\"\n",
    "test_folder = \"Error Dataset/images\"\n",
    "\n",
    "for folder in (train_folder, validation_folder, test_folder):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# Create list of image ids\n",
    "train_ids = pd.read_csv(train_csv)[\"image_id\"].astype(str).tolist()\n",
    "val_ids = pd.read_csv(validation_csv)[\"image_id\"].astype(str).tolist()\n",
    "test_ids = pd.read_csv(test_csv)[\"image_id\"].astype(str).tolist()\n",
    "\n",
    "# Split Images\n",
    "for fname in os.listdir(input_folder):\n",
    "    \n",
    "    image_id = os.path.splitext(fname)[0]\n",
    "    image_path = os.path.join(input_folder, fname)\n",
    "\n",
    "    if image_id in train_ids:\n",
    "        dst_folder = train_folder\n",
    "    elif image_id in val_ids:\n",
    "        dst_folder = validation_folder\n",
    "    elif image_id in test_ids:\n",
    "        dst_folder = test_folder\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    shutil.move(image_path, os.path.join(dst_folder, fname))\n",
    "\n",
    "print(\"Images have been split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3746329b-aeb7-4676-be59-57c781269e32",
   "metadata": {},
   "source": [
    "## Add background images to training, validation, and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e025785-ed2d-4041-8779-7a000f7d25aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bg(source, destination):\n",
    "\n",
    "    destination_images = [f for f in os.listdir(destination)]\n",
    "    source_images = [f for f in os.listdir(source)]\n",
    "\n",
    "    num_to_move = len(destination_images)\n",
    "\n",
    "    selected_images = random.sample(source_images, num_to_move)\n",
    "\n",
    "    for img in selected_images:\n",
    "        src_path = os.path.join(source, img)\n",
    "        dst_path = os.path.join(destination, img)\n",
    "        shutil.move(src_path, dst_path)\n",
    "\n",
    "    print(f\"Moved {num_to_move} images from source to destination.\")\n",
    "\n",
    "add_bg(\"images\", r\"YOLODataset/train/images\")\n",
    "add_bg(\"images\", r\"YOLODataset/val/images\")\n",
    "add_bg(\"images\", \"Error Dataset/images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777765e3-544e-43be-bc3d-6b755c1b5901",
   "metadata": {},
   "source": [
    "# Convert to YOLO format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341867fb-e059-4b4e-8a48-1eef19c05f66",
   "metadata": {},
   "source": [
    "## Convert annotations to text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a2a2a8-c049-4dab-9915-2bc345d32f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yolo_txt_files(csv_path, label_dir, img_size=1024):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    os.makedirs(label_dir, exist_ok=True)\n",
    "\n",
    "    grouped = df.groupby('image_id')\n",
    "\n",
    "    for image_id, group in grouped:\n",
    "        txt_file = os.path.join(label_dir, f\"{image_id}.txt\")\n",
    "        with open(txt_file, \"w\") as f:\n",
    "            for _, row in group.iterrows():\n",
    "                class_id = row['class_id']\n",
    "                x_min, y_min, x_max, y_max = row['x_min'], row['y_min'], row['x_max'], row['y_max']\n",
    "\n",
    "                x_center = ((x_min + x_max) / 2) / img_size\n",
    "                y_center = ((y_min + y_max) / 2) / img_size\n",
    "                width = (x_max - x_min) / img_size\n",
    "                height = (y_max - y_min) / img_size\n",
    "\n",
    "                f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
    "\n",
    "    print(f\"YOLO .txt files created in: {label_dir}\")\n",
    "\n",
    "csv_path = \"training.csv\"\n",
    "label_dir = \"YOLODataset/train/labels\"\n",
    "img_size = 1024\n",
    "\n",
    "create_yolo_txt_files(csv_path, label_dir, img_size)\n",
    "\n",
    "csv_path = \"validation.csv\"\n",
    "label_dir = \"YOLODataset/val/labels\"\n",
    "\n",
    "create_yolo_txt_files(csv_path, label_dir, img_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8085ad5-e357-41da-95b6-657713e0a24a",
   "metadata": {},
   "source": [
    "## Create a single annotation class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21532b9-10e6-488e-a315-9dce6eed1201",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in [\"train\", \"test\"]:\n",
    "    annotation_dir = f\"/content/drive/MyDrive/YOLODataset/{split}/labels\"\n",
    "\n",
    "    for file_name in os.listdir(annotation_dir):\n",
    "        file_path = os.path.join(annotation_dir, file_name)\n",
    "        with open(file_path, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        with open(file_path, \"w\") as file:\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                parts[0] = \"0\"\n",
    "                file.write(\" \".join(parts) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12136e41-3f5a-4fea-86e0-e59369fa1625",
   "metadata": {},
   "source": [
    "## Create YAML file for Ultralytics requirements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec253b10-5167-4210-ae0c-dc79701775ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yaml_file(output_path, dataset_path, num_classes, class_names):\n",
    "\n",
    "    data = {\n",
    "        \"path\": dataset_path,\n",
    "        \"train\": \"train/images\",\n",
    "        \"val\": \"val/images\",\n",
    "        \"nc\": num_classes,\n",
    "        \"names\": class_names\n",
    "    }\n",
    "\n",
    "    with open(output_path, \"w\") as file:\n",
    "        yaml.dump(data, file, default_flow_style=False)\n",
    "    print(f\"YAML file created at: {output_path}\")\n",
    "\n",
    "dataset_base_path = \"YOLOExperiment\"\n",
    "output_yaml_path = \"YOLOExperiment.yaml\"\n",
    "number_of_classes = 1\n",
    "class_names_list = [\n",
    "    \"Abnormality\"\n",
    "]\n",
    "\n",
    "create_yaml_file(output_yaml_path, dataset_base_path, number_of_classes, class_names_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
