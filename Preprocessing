folder_path = r'D:\Downloads\vinbigdata-chest-xray-abnormalities-detection (1)\train'
folder_path_test = r'D:\Downloads\vinbigdata-chest-xray-abnormalities-detection (1)\testing'
dicom_files = [f for f in os.listdir(folder_path) if f.endswith('.dicom')]
dicom_files_test = [f for f in os.listdir(folder_path_test) if f.endswith('.dicom')]
batch_size = 20
processed_count = 0
image_ids = []
shape = (1500, 512, 512, 1)
file_path = 'D:\\Resized_Data.h5'

# Resizing images into .hdf5 file

with h5py.File(file_path, 'w') as hdf5_file:
    dataset = hdf5_file.create_dataset('images', shape=shape, dtype=np.uint16, fillvalue=0)

print("HDF5 file created with dataset of shape:", shape)

with h5py.File(file_path, 'r+') as hdf5_file:  # Open the file in read/write mode
    dataset = hdf5_file['images']
    
    for i in range(0, len(dicom_files_test), batch_size):
        # Create an empty list to store the resized images for this batch
        resized_images = []
        
        # Process the current batch of files
        for file in dicom_files_test[i:i+batch_size]:
            dicom_path = os.path.join(folder_path_test, file)
            dicom_image = pydicom.dcmread(dicom_path)
            
            # Get the pixel array from the dicom file
            image_data = dicom_image.pixel_array
            
            image_resize = cv2.resize(image_data,(512,512))
            
            # Convert the resized image back to a NumPy array and ensure it has a single channel (grayscale)
            resized_array = np.array(image_resize)[..., np.newaxis]
            
            # Append to the list of resized images
            resized_images.append(resized_array)
    
            image_ids.append(file)
    
        # Stack the batch of resized images into a 4D NumPy array (batch_size, 512, 512, 1)
        resized_images_np = np.stack(resized_images, axis=0)
        
        dataset[i:i + batch_size, :, :, :] = resized_images_np
        
        # Update the processed count
        processed_count += len(resized_images)
        
        print(f"Processed and saved {processed_count} images so far.")

# Resizing images into .npy file

for i in range(0, len(dicom_files_test), batch_size):
    # Create an empty list to store the resized images for this batch
    resized_images = []
    
    # Process the current batch of files
    for file in dicom_files_test[i:i+batch_size]:
        dicom_path = os.path.join(folder_path_test, file)
        dicom_image = pydicom.dcmread(dicom_path)
        
        # Get the pixel array from the dicom file
        image_data = dicom_image.pixel_array
        
        image_resize = cv2.resize(image_data,(512,512))
        
        # Convert the resized image back to a NumPy array and ensure it has a single channel
        resized_array = np.array(image_resize)[..., np.newaxis]
        
        # Append to the list of resized images
        resized_images.append(resized_array)

        image_ids.append(file)

    # Stack the batch of resized images into a 4D NumPy array (batch_size, 512, 512, 1)
    resized_images_np = np.stack(resized_images, axis=0)
    
    # Save this batch to the .npy file on the thumb drive
    if processed_count == 0:
        # First batch, save the file
        np.savez_compressed(thumbdrive_path, resized_images_np)
    else:
        # Append to the existing file
        with open(thumbdrive_path, 'ab') as f:
            np.save(f, resized_images_np)
    
    # Update the processed count
    processed_count += len(resized_images)
    
    print(f"Processed and saved {processed_count} images so far.")

# Resizing Bounding Boxes

data = pd.read_csv("D:\\Downloads\\train.csv")

for x in range(0,67914):
    if x%5000 == 0:
        print("test")
    if data.loc[x, "class_id"] != 14:
        file = folder_path + "\\" + data.loc[x, "image_id"] + ".dicom"
        shape = ((pydicom.dcmread(file)).pixel_array).shape
        formula_x = 512 / shape[1]
        formula_y = 512 / shape[0]
        data.loc[x, "x_min"] = int(formula_x * float(data.loc[x, "x_min"]))
        data.loc[x, "y_min"] = int(formula_y * float(data.loc[x, "y_min"]))
        data.loc[x, "x_max"] = int(formula_x * float(data.loc[x, "x_max"]))
        data.loc[x, "y_max"] = int(formula_y * float(data.loc[x, "y_max"]))
data.to_csv('D:\\preprocessed.csv', index = False)
